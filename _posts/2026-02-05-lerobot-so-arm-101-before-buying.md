---
layout: post
title: LeRobot SO ARM 101 처음 사기전에 알아두면 좋은 내용 (Physical AI)
excerpt: Things to know before buying LeRobot SO ARM 101
author: haandol
email: ldg55d@gmail.com
tags: physical-ai lerobot so-arm-101 robotics
publish: true
---

## TL;DR

- 100불이 아니라 60만원 이상 든다
- 시간과 공간도 생각보다 많이 필요하다
- 로컬 GPU 머신이 필요하다

## 시작하며

재작년쯤 피지컬 AI 프로젝트를 처음 해보고 알리에서 로봇팔을 하나 샀었다. 총 17만원으로 아두이노와 조이패드로 제어하는 로봇팔이었다. 싸다고 생각해서 무지성으로 사 놓고 이것저것 해보니 '피지컬 AI 를 취미로 공부하는 거면 로봇 팔이 진짜 필요한가?' 라는 생각이 들었다. 어차피 AI 가 피지컬을 제어하는거고, AI 가 핵심인데 굳이 피지컬이 필요한가? (집도 좁은데)

그래서 시뮬레이션에서도 해볼수 있는게 많고, 어차피 파운데이션 모델과 월드모델이 충분히 발전하면 sim2real 갭은 없는거 아닐까? 하는 생각을 가지게 되었다.

그러다 pollen robotics 의 reachy mini 를 봤다. 효용적으로는 진짜 아무 의미 없는 로봇인데 엄청 인기가 많은 것을 보고는, `아 그래도 역시 티 내기에는 물리적인 로봇을 다뤄보긴 해야하는구나` 하는 생각을 해서 lerobot 팔을 하나 샀다.

본 글은 로봇팔을 사고 나서 미리 알고 샀으면 좋았을 걸 하는 생각을 적어두는 포스트모템 같은 글이다.

![로봇 셋업](/assets/img/2026/0205/setup.jpg)

## 1. 진짜 사야하나 한번 더 생각해보기

일단 사고 다 돌려보고 나서 드는 생각은, 가성비가 별로라는 것이었다. LeRobot 이 없었으면 더 비싼 돈에 테스트해봐야 했었다는 것을 감안해도 그랬다.

어차피 시뮬레이션에서 다 해볼 수 있는 내용이며, 피지컬 AI는 결국 AI 가 핵심이라 로봇 자체가 꼭 필요한건 아니었다. 한달정도 대여만 할 수 있었다면 안사도 좋았을 걸 하는 생각이 든다.

## 2. 돈이 생각보다 많이 든다

100불이라고 주장하는건 좀 사라졌으면 좋겠는데, 프린팅 비용만 100불인거 같다. 아두이노에 개별 연결해서 제어하던 알리발 6DoF 로봇에 비해, 르로봇 모터들은 나름 스마트 모터를 쓰고 있기 때문에 마스터 버스 하나에서 버스아이디로 제어하는 방식을 쓰고 있으며, 덕분에 엄청 구성이 간단하다. 대신 모터 각각이 3만원정도 하며 리더암과 팔로워암 각각에 모터가 6개씩 들어가니까 12 * 3 해서 모터값만 36만원이상 든다.

카메라 2개와 (손목, 탑) usb 허브, 어댑터들 (12v, 5v) 클램프, 버스 등이 추가로 필요한데 다 하면 대략 45만원이 넘는다. wowrobo 같은데서 해외 직구로 사면 관세가 붙기 때문에 대충 50만원 정도 든다. (물품가격 + 운송비 합산 150달러 초과시 관세부과) 여튼 대략 60만원이상 든다고 생각하고 이만한 가치가 있는지 한번 생각해볼 필요가 있다.

## 3. 시간과 장소가 생각보다 많이 필요하다

돈을 떠나서 장소도 꽤 많이 필요로 하는데, 리더암과 팔로워 암을 설치할 공간과 카메라를 설치할 공간, 전원선을 각각의 팔과 연결할 수 있는 지 여부 등 공간을 꽤 잡아먹는 편이다. 15평짜리 집에서 부부 둘이 좁게좁게 지내고 있는 나로서는 사실 돈보다 공간을 투자해야 한다는게 더 큰 문제였다.

시간도 꽤 드는데, 조립하는게 처음이라면 3시간 정도 걸릴거고 (내 경우), 데이터셋 쌓는데도 한두시간 걸린다. 금전여유가 있고 굳이 로봇조립 안해봐도 된다면 10만원정도 내고 완조립 제품을 받는 옵션을 선택하는 게 그렇게 나쁜 선택은 아닌거 같다.

본인이 비전기반 머신러닝을 안해봤다면 데이터 셋 쌓는것도 시행착오를 거칠건데, 예를 들면 조명의 상태가 고르지 않다거나, 탑 카메라의 위치가 전체 씬을 조망하지 못하고 특정경우에 오브젝트가 자꾸 가려진다거나, 하는 등의 내용이다. 데이터셋이 잘못쌓이면 GR00T 은 좀 괜찮지만 ACT 는 잘 동작안할 가능성이 높아서 다시 쌓아야 할 것이다.

아래 두 영상은 모두 로컬에서 리더암으로 데이터를 모은 뒤, EC2 에서 학습하고 학습된 모델을 다시 로컬로 가져와서 실행한 결과이다.

먼저 ACT 로 학습해서 실제 시연한 영상이다.

<iframe width="560" height="315" src="https://www.youtube.com/embed/Kwr9zjF7PXA" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

다음은 GR00T 으로 시연한 영상이다.

<iframe width="560" height="315" src="https://www.youtube.com/embed/6gJNV_hN0dM" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

## 4. 로컬 GPU 머신이 필요하다

나는 집에 컴퓨터가 없고, 회사에서 준 맥북프로 한대만 있다. 그래서 처음부터 모델학습은 AWS 에서 하기로 생각하고 있었다. (직원은 실험용으로는 거의 무제한으로 쓸 수 있기 때문)

대부분의 환경설정 문서들은 nvidia + 리눅스 머신이라고 가정하고 작성되어 있기 때문에, 만약 해당 머신이 없다면 클라우드 GPU 를 쓴다는 것을 전제로 해야한다.

AWS G6e.16xlarge 기준 학습 자체는 대략 ACT 는 3시간, GR00T N1.5 는 대략 6시간 걸린거 같으니 참고하면 좋을거 같다. 참고로 속도는 멀티 GPU 쓰면 더 빠르게 학습할 수 있다. 나는 Isaac Sim 을 띄워서 이것저것 해봐야해서 vCPU 가 높은 머신을 선택하다보니 g6e.16xlarge 를 썼다.

데이터 쌓고 하는 것들은 맥북 프로만 있어도 된다. 하지만 학습하는 과정에서 GPU 가 필요하고, 학습한 모델을 가지고 로봇을 돌릴 때 또 GPU 가 필요하다.

ACT 나 GR00T, PiZero 는 다들 모델이 작아서 맥북프로 M3 16인치 48GB 정도면 10~5Hz 속도로 돌아간다. (발발거리지만 돌아가긴함) 하지만 본인이 가지고 있는 로컬 머신이 맥북에어 라든지 서피스북 이라면 로봇을 돌릴 때도 AWS gpu 자원을 써야하기 때문에 돈이 생각보다 많이 든다고 보면 된다. (사실 그냥 돈 좀 보태서 jetson orin nano 하나 사는게 더 나을지도)

## 5. 리더암만 사는 것도 방법이다

말그대로 리더암만 사는 것도 생각해볼만하다. 보통 시뮬레이션에서 학습할 때 데이터 쌓기 어려운게, 리더암으로 쌓는 데이터에 비해 덜 매끄럽게 쌓이기 때문인데, 이것은 스페이스 마우스나 조이스틱을 써도 쉽게 해결하기는 어렵다. (키보드 조작보다는 훨씬 낫지만). 특히 ACT 는 모방학습(Imitation Learning) 이기 때문에 학습데이터에서 로봇의 궤적이 매끄럽지 않다면 굉장히 성공률이 낮아질 가능성이 높다.

이런 경우를 위해서 그냥 모든 것을 다 클라우드에 두고, 리더암을 클라우드에 있는 IsaacSim 에 연결해서 시뮬레이션 상의 팔을 제어하고, 해당 데이터로 그대로 학습 및 인퍼런스까지 한번에 해버리는 것도 나쁘지 않다. 나도 로봇팔이 오기전에는 엑스박스 컨트롤러로 똑같이 했었는데 은근 나름 잘 됐었다.

참고로 lerobot 으로 IsaacSim 을 제어하는 [leisaac](https://github.com/LightwheelAI/leisaac) 같은 프로젝트들도 로컬에 IsaacSim 을 띄운다는 것을 전제로 작성되어 있다. 하지만 나는 로컬에 nvidia 환경이 없기 때문에 EC2 에 있는 IsaacSim 에 ZMQ 를 띄우고, 해당 큐를 통해 로컬에 있는 리더암의 액션데이터를 실시간으로 전달해서 IsaacSim 내의 팔로워암을 움직이게 했다. 관련 변경사항은 [여기](https://github.com/LightwheelAI/leisaac/compare/main...haandol:leisaac:main)에서 확인할 수 있다. 이 모든 과정은 Kiro 로 작성했으며, Claude Opus 4.5 덕분에 짧은 디버깅 이후에 잘 동작하는 것을 확인할 수 있었다.

여튼 리더암이 있으면 그래도 로봇을 사긴 산 느낌과 함께 절반도 안되는 가격 (카메라가 필요없기 때문), 엄청 좁은 공간만 차지함, 고품질의 데이터 등 여러가지 장점이 있기때문에 최고의 절충안이 리더암만 사는거 아닌가 하는 생각도 있다.

## 6. 휴머노이드면 퀘스트나 비전프로를 사면 된다

최근엔 휴머노이드 하려면 리더암 두개로 매트릭스처럼 제어하지 않고 퀘스트나 비전프로를 가지고 제스처 인식을 해서 데이터를 쌓는다. 따라서 xlerobot 뭐 그런거 팔 두개 130만원 쓰고 살바에는 그냥 퀘스트3 만 사는것도 괜찮은 방법 같다.

여튼 여기까지가 내가 대충 돌려보면서 느낀 결과이고 사기전부터 이미 이런 생각을 그대로 가지고 있었는데, 사고나서 뭔가 달라지지는 않았다.

한가지 달라진건 똑같은 기술에 똑같은 과정을 시뮬레이션으로 보여주면 사람들이 모두 `뭐 어쩌라고` 같은 반응이었는데, 실제 팔로 보여주면 `이건 좀 괜찮을지도` 하는 반응이라는 것이다. (이것도 사실 예전에 피지컬 AI 프로젝트 처음 할 때 같은 반응이었다.)

## 마치며

cosmos predict 같은 월드 모델이 점점 좋아지고, gr00t mimic 이나 dreams 같은 파이프라인들도 정교해지면서 앞으로 피지컬 AI 공부를 할 때 아이러니하게도 피지컬한 환경이 필요하지 않을수도 있겠다는 생각이 든다.
